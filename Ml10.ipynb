{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a1a91db-7fe4-4593-9a0a-76bdd1f07954",
   "metadata": {},
   "source": [
    "# Doğal Dil İşleme - (Natural Language Processing - NLP) / Hesaplamalı Bilim (Computional Linguistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb28d24-7d3c-43af-8204-9d00893ebdad",
   "metadata": {},
   "source": [
    "**Hedefler**\n",
    "* NLU (Natural Language Understanding)\n",
    "* NLG (Natural Language Generation)\n",
    "\n",
    "**Yaklaşımlar**\n",
    "* Linguistic (Dilbilim) Yaklaşımı\n",
    "    * Pragmatics (Kullanımbilim)\n",
    "    * Semantics (Anlambilim)\n",
    "    * Syntax (Sözdizim)\n",
    "    * Morphology (Şekilbilim)\n",
    "* İstatistiksel Yaklaşımlar\n",
    "    * N-gram\n",
    "    * TF-IDF\n",
    "    * Word-Gram\n",
    "    * BOW (Bag of Words, Kelime Çantaları)\n",
    "* Hybrid (Hibrit) Yaklaşımlar\n",
    "\n",
    "<br>\n",
    "\n",
    "**Örnek: Yazar Tanıma**\n",
    "* Linguistic (Dilbilim) Yaklaşımı\n",
    "    * POS-Tagging (Part of Speech Tagging, Metin Parçası Etiketleme)\n",
    "* İstatistiksel Yaklaşımlar\n",
    "    * İstatistiksel Dağılım\n",
    "* Hybrid (Hibrit) Yaklaşımlar\n",
    "    * Metindeki kelime tiplerinin dağılımı ve cumle yapıları\n",
    "    \n",
    "<hr>\n",
    "\n",
    "**Örnek: Metin Sınıflandırma (Örn. Çağrı merkezi, sosyal ağlar, mailler vb.)**\n",
    "* Linguistic (Dilbilim) Yaklaşımı\n",
    "    * Örüntü tanımı (isim tamlaması, sıfat tamlaması vb.)\n",
    "* İstatistiksel Yaklaşımlar\n",
    "    * İstatistiksel Dağılım\n",
    "* Hybrid (Hibrit) Yaklaşımlar\n",
    "    * Örüntü dağılımı sınıflandırma\n",
    "        \n",
    "<hr>\n",
    "\n",
    "**Örnek: Duygusal Kutupsallık (Sentimental Polarity), Fikir Madenciliği(Opinion Mining)**\n",
    "* Linguistic (Dilbilim) Yaklaşımı\n",
    "    * Kelime anlam çıkarımı (olumlu veya olumsuz)\n",
    "* İstatistiksel Yaklaşımlar\n",
    "    * Kelime tanımlı sözlükler veya örüntüler\n",
    "* Hybrid (Hibrit) Yaklaşımlar\n",
    "    * Duygu analizi (Sentimental Analysis)\n",
    "        \n",
    "<hr>\n",
    "\n",
    "**Örnek: Anomali Yakalama (Saldırgan, virüs veya tehdit)**\n",
    "* Linguistic (Dilbilim) Yaklaşımı\n",
    "* İstatistiksel Yaklaşımlar\n",
    "    * Anomali yakalama ve kelime dağılımları\n",
    "* Hybrid (Hibrit) Yaklaşımlar\n",
    "    * Anahtar kelime çıkarımı\n",
    "    \n",
    "<br><br>\n",
    "\n",
    "**Gerçek Uygulamalar**\n",
    "* Duygu Analizi (Sentimental Analysis)\n",
    "* Metin Sınıflandırma (Text Categorization)\n",
    "* Metin Özetleme (Document Summarization)\n",
    "* Soru Cevaplama (uestion Answering)\n",
    "* Etiket Bulutları ve Anahtar Kelime Çıkarımı\n",
    "\n",
    "<br><br>\n",
    "\n",
    "**Bazı Yabancı DDİ Kütüphaneleri**\n",
    "* NLTK: nltk.org\n",
    "* SpaCy: spacy.io\n",
    "* Stanford NLP\n",
    "* OpenNLP: Apache: opennlp.apache.org\n",
    "* Rapid Automatic Keyword Extraction (RAKE)\n",
    "* Amueller Word Cloud\n",
    "* Tensor Flow: Word2Vec\n",
    "\n",
    "<br><br>\n",
    "\n",
    "**Bazı Türkçe DDİ Kütüphaneleri**\n",
    "* Zemberek (zembereknlp.blogspot.com)\n",
    "* İTÜ (tools.nlp.itu.edu.tr)\n",
    "* Tspell (tspell.sourceforge.net/hakkinda.html)\n",
    "* Yıldız Teknik Üniversitesi: Kemik: (www.kemik.yildiz.edu.tr)\n",
    "* Wordnet (Balkanet)\n",
    "* TrMorph (coltekin.net/cagri/trmorph)\n",
    "* TSCorpus (tscorpus.com)\n",
    "* Metu-Sabancı Tree Bank ve İTÜ Doğrulama Kümesi (web.itu.edu.tr/gulsenc/treebanks.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af5e2ae4-d637-45bf-b424-c411484885e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2404fb8c-476c-4bcb-b2e1-5e1676eb783b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Review</td>\n",
       "      <td>Liked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>The whole experience was underwhelming</td>\n",
       "      <td>and I think we'll just go to Ninja Sushi next...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>Then</td>\n",
       "      <td>as if I hadn't wasted enough of my life there</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1001 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review  \\\n",
       "0                                                Review   \n",
       "1                              Wow... Loved this place.   \n",
       "2                                    Crust is not good.   \n",
       "3             Not tasty and the texture was just nasty.   \n",
       "4     Stopped by during the late May bank holiday of...   \n",
       "...                                                 ...   \n",
       "996   I think food should have flavor and texture an...   \n",
       "997                            Appetite instantly gone.   \n",
       "998   Overall I was not impressed and would not go b...   \n",
       "999              The whole experience was underwhelming   \n",
       "1000                                               Then   \n",
       "\n",
       "                                                  Liked  \n",
       "0                                                 Liked  \n",
       "1                                                     1  \n",
       "2                                                     0  \n",
       "3                                                     0  \n",
       "4                                                     1  \n",
       "...                                                 ...  \n",
       "996                                                   0  \n",
       "997                                                   0  \n",
       "998                                                   0  \n",
       "999    and I think we'll just go to Ninja Sushi next...  \n",
       "1000      as if I hadn't wasted enough of my life there  \n",
       "\n",
       "[1001 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colons = [\"Review\",\"Liked\"]\n",
    "yorumlar = pd.read_csv(\"../Docs/Restaurant_Reviews.csv\", names = colons)\n",
    "yorumlar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dabec755-7e95-4631-95ba-af761f620be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Tolga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d0e4e44-49e2-4747-a0e3-7e1ad1f0f96b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mType:\u001b[0m        PorterStemmer\n",
       "\u001b[1;31mString form:\u001b[0m <PorterStemmer>\n",
       "\u001b[1;31mFile:\u001b[0m        c:\\users\\tolga\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\nltk\\stem\\porter.py\n",
       "\u001b[1;31mDocstring:\u001b[0m  \n",
       "A word stemmer based on the Porter stemming algorithm.\n",
       "\n",
       "    Porter, M. \"An algorithm for suffix stripping.\"\n",
       "    Program 14.3 (1980): 130-137.\n",
       "\n",
       "See https://www.tartarus.org/~martin/PorterStemmer/ for the homepage\n",
       "of the algorithm.\n",
       "\n",
       "Martin Porter has endorsed several modifications to the Porter\n",
       "algorithm since writing his original paper, and those extensions are\n",
       "included in the implementations on his website. Additionally, others\n",
       "have proposed further improvements to the algorithm, including NLTK\n",
       "contributors. There are thus three modes that can be selected by\n",
       "passing the appropriate constant to the class constructor's `mode`\n",
       "attribute:\n",
       "\n",
       "- PorterStemmer.ORIGINAL_ALGORITHM\n",
       "\n",
       "    An implementation that is faithful to the original paper.\n",
       "\n",
       "    Note that Martin Porter has deprecated this version of the\n",
       "    algorithm. Martin distributes implementations of the Porter\n",
       "    Stemmer in many languages, hosted at:\n",
       "\n",
       "    https://www.tartarus.org/~martin/PorterStemmer/\n",
       "\n",
       "    and all of these implementations include his extensions. He\n",
       "    strongly recommends against using the original, published\n",
       "    version of the algorithm; only use this mode if you clearly\n",
       "    understand why you are choosing to do so.\n",
       "\n",
       "- PorterStemmer.MARTIN_EXTENSIONS\n",
       "\n",
       "    An implementation that only uses the modifications to the\n",
       "    algorithm that are included in the implementations on Martin\n",
       "    Porter's website. He has declared Porter frozen, so the\n",
       "    behaviour of those implementations should never change.\n",
       "\n",
       "- PorterStemmer.NLTK_EXTENSIONS (default)\n",
       "\n",
       "    An implementation that includes further improvements devised by\n",
       "    NLTK contributors or taken from other modified implementations\n",
       "    found on the web.\n",
       "\n",
       "For the best stemming, you should use the default NLTK_EXTENSIONS\n",
       "version. However, if you need to get the same results as either the\n",
       "original algorithm or one of Martin Porter's hosted versions for\n",
       "compatibility with an existing implementation or dataset, you can use\n",
       "one of the other modes instead.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30837a4d-18a8-4287-a9f5-47bebbf1996a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing (Önişleme)\n",
    "derlem = []\n",
    "for i in range(1000):\n",
    "    yorum = re.sub('[^a-zA-Z]',' ',yorumlar['Review'][i])\n",
    "    yorum = yorum.lower()\n",
    "    yorum = yorum.split()\n",
    "    yorum = [ps.stem(kelime) for kelime in yorum if not kelime in set(stopwords.words('english'))]\n",
    "    yorum = ' '.join(yorum)\n",
    "    derlem.append(yorum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43b6bff3-1601-458d-ac68-fa0c3f76b1dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1000, 1001]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14452\\2956735625.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Bağımlı değişken\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myorumlar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mgnb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2415\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"At least one array required as input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2417\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    333\u001b[0m             \u001b[1;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[1;33m%\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1000, 1001]"
     ]
    }
   ],
   "source": [
    "# Feautre Extraction ( Öznitelik Çıkarımı)\n",
    "# Bag of Words (BOW)\n",
    "\n",
    "cv = CountVectorizer(max_features = 2000)\n",
    "# Bağımsız değişken\n",
    "X = cv.fit_transform(derlem).toarray() \n",
    "# Bağımlı değişken\n",
    "y = yorumlar.iloc[:,1].values \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,y_train)\n",
    "\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d180c9bc-40ba-4f75-8836-afac3b8dfc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `cv` not found.\n"
     ]
    }
   ],
   "source": [
    "?cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96898eb-9c05-41d0-9bfa-f615b5ebb978",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
