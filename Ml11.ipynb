{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cb26ae1-8f68-4751-8375-5c78ebb481b2",
   "metadata": {},
   "source": [
    "# Yapay Sinir Ağları (Artificial Neural Network - ANN)\n",
    "\n",
    "**Aktivasyon Fonksiyonları**\n",
    "\n",
    "Nöron Üzerindeki Sinyal = w1(x1) + w2(x2) + w3(x3)\n",
    "\n",
    "Nöron Üzerindeki Aktivasyon = ${\\displaystyle \\phi}$ [w1(x1) + w2(x2) + w3(x3)]\n",
    "\n",
    "<br><br>\n",
    "\n",
    "* Hemen hemen bütün fonksiyonlar kullanılır fakat yaygın olanları:\n",
    "    * Threshold Function (Adım Fonksiyonu)\n",
    "    * Sigmoid Function\n",
    "    \n",
    "## Sigmoid Fonksiyon\n",
    "\n",
    "**Hatırlatma Logistic Regression**\n",
    "\n",
    "* ${\\displaystyle \\sigma (t) = {\\frac {e^t}{e^t + 1}} = {\\frac {1}{1 + e^{-t}}}}$\n",
    "\n",
    "* ${\\displaystyle t = \\beta_0 + \\beta_1 x, t = A + Bx}$\n",
    "\n",
    "* ${\\displaystyle p(x)= {\\frac {1}{1 + e^{-(\\beta_0 + \\beta_1 x)}}}}$\n",
    "\n",
    "* ${\\displaystyle \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_m x_m = \\beta_0 + {\\sum_{i=1}^m} \\beta_i x_i }$\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Adım Fonksiyonu (Step Function)**\n",
    "${\\displaystyle \\phi (x) = 1}$\n",
    "\n",
    "<hr>\n",
    "\n",
    "**S Fonksiyonu (Sigmoid Function)**\n",
    "${\\displaystyle \\phi (x) = {\\frac {1}{1 + e^{-x}}}}$\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Düzleştirilmiş Fonksiyon (Rectifier)**\n",
    "${\\displaystyle \\phi (x) = max(x,0)}$\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Hiperbolik Tanjant (Hyperbolic Tangent - tanh)**\n",
    "${\\displaystyle \\phi (x) = {\\frac {1 - e^{-2x}}{1 + e^(-2x)}}}$\n",
    "\n",
    "## Gradyan Alçalış (Gradient Descendent)\n",
    "\n",
    "**Öğrenme Oranı ve Gradyan İniş**\n",
    "* Büyük öğrenme oranı (Big learning rate)\n",
    "* Küçük öğrenme oranı (Small learning rate)\n",
    "\n",
    "\n",
    "## Geri Yayılım (Backpropogation)\n",
    "\n",
    "**Adımlar**\n",
    "* **Adım 1:** Bütün ağı rastgele sayılarla (sıfıra yakın ama sıfırdan farklı) ilklendirme\n",
    "* **Adım 2:** Veri kümesinden ilk satır (her öznitelik bir nöron olacak şekilde) giriş katmanından verilir\n",
    "* **Adım 3:** **İleri yönlü yayılım yapılarak**, YSA istenen sonucu verene kadar güncellenir\n",
    "* **Adım 4:** Gerçek ve çıktı arasındaki fark alınarak hata (error) hesaplanır\n",
    "* **Adım 5:** **Geri yayılım yapılarak**, her sinapsis üzerindeki ağırlık, hatadan sorumlu olduğu miktarda değiştirilir. Değiştirilme miktarı ayrıca öğrenme oranına da bağlıdır\n",
    "* **Adım 6:** Adım 1-5 arasındaki adımları istenen sonucu elde edene kadar güncelleme (Takviyeli Öğrenme - Reinforced Learning) veya eldeki bütün verileri ilgili ağda çalıştırdıktan sonra tek seferde güncelleme (Yığın Öğrenme - Batch Learning)\n",
    "* **Adım 7:** Bütün eğitim kümesi çalıştırıldıktan sonra bir tur (epoch) tamamlanmış olur, aynı veri kümeleri kullanılarak tur tekrarları yapılır\n",
    "\n",
    "<br>\n",
    "\n",
    "**Derin Öğrenme Kütüphaneleri**\n",
    "* PyTorch (pytorch.org)\n",
    "* TensorFlow (tensorflow.org)\n",
    "* Caffe (caffe.berkeleyvision.org)\n",
    "* Keras (keras.io)\n",
    "* DeepLearning4J (deeplearning4j.org)\n",
    "* ve diğerleri...\n",
    "\n",
    "<br>\n",
    "\n",
    "**Kodlama ve Kütüphaneler**\n",
    "* CPU ve GPU farkları\n",
    "    * Derin öğrenme için GPU\n",
    "    * Küçük ağlar için CPU\n",
    "* Paralel işleme (YSA forward ve Backpropoation sırasında)\n",
    "* Derin öğrenmenin sıfırdan kodlayarak başlaması\n",
    "    * Theano (GPU desteği bulunmakta)\n",
    "    * TensorFlow (Google)\n",
    "* Hazır bazı ağların ve kütüphanelerin kullanımı (üst seviye yapay sinir ağı kütüphanesi)\n",
    "    * Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e989f672-2f0c-4a9a-ab5c-a42abd6af742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe36b70e-9429-40cd-adcb-629b2199721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "veriler = pd.read_csv(\"../Docs/Churn_Modelling.csv\")\n",
    "\n",
    "# Veri ön işleme\n",
    "\n",
    "X= veriler.iloc[:,3:13].values\n",
    "Y = veriler.iloc[:,13].values\n",
    "\n",
    "\n",
    "#encoder: Kategorik -> Numeric\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "X[:,1] = le.fit_transform(X[:,1])\n",
    "\n",
    "le2 = preprocessing.LabelEncoder()\n",
    "X[:,2] = le2.fit_transform(X[:,2])\n",
    "\n",
    "ohe = ColumnTransformer([(\"ohe\", OneHotEncoder(dtype=float),[1])],\n",
    "                        remainder=\"passthrough\"\n",
    "                        )\n",
    "X = ohe.fit_transform(X)\n",
    "X = X[:,1:]\n",
    "\n",
    "# Verilerin eğitim ve test için bölünmesi\n",
    "\n",
    "x_train, x_test,y_train,y_test = train_test_split(X,Y,test_size=0.33, random_state=0)\n",
    "\n",
    "\n",
    "# Verilerin Ölçeklenmesi\n",
    "\n",
    "sc=StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(x_train)\n",
    "X_test = sc.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14e18a31-0c85-4081-8c54-5d9bad654c7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('Keyword argument not understood:', 'init')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11076\\2129964045.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# classifier.add(Dense(6, init = 'uniform', activation = 'relu' , input_dim = 11))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'uniform'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'uniform'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\core\\dense.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[0;32m    109\u001b[0m                \u001b[0mbias_constraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m                **kwargs):\n\u001b[1;32m--> 111\u001b[1;33m     super(Dense, self).__init__(\n\u001b[0m\u001b[0;32m    112\u001b[0m         activity_regularizer=activity_regularizer, **kwargs)\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    627\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 629\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, trainable, name, dtype, dynamic, **kwargs)\u001b[0m\n\u001b[0;32m    339\u001b[0m     }\n\u001b[0;32m    340\u001b[0m     \u001b[1;31m# Validate optional keyword arguments.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m     \u001b[0mgeneric_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m     \u001b[1;31m# Mutable properties\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mvalidate_kwargs\u001b[1;34m(kwargs, allowed_kwargs, error_message)\u001b[0m\n\u001b[0;32m   1172\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1173\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1174\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwarg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'init')"
     ]
    }
   ],
   "source": [
    "#3 Yapay Sinir ağı\n",
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(6, init = 'uniform', activation = 'relu' , input_dim = 11))\n",
    "\n",
    "classifier.add(Dense(6, init = 'uniform', activation = 'relu'))\n",
    "\n",
    "classifier.add(Dense(1, init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss =  'binary_crossentropy' , metrics = ['accuracy'] )\n",
    "\n",
    "classifier.fit(X_train, y_train, epochs=50)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fb69568-c3d5-4a84-b770-4cce87431c8c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m      \u001b[0mclassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mType:\u001b[0m           Sequential\n",
       "\u001b[1;31mString form:\u001b[0m    <keras.engine.sequential.Sequential object at 0x00000212873ADD50>\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\tolga\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\keras\\engine\\sequential.py\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "`Sequential` groups a linear stack of layers into a `tf.keras.Model`.\n",
       "\n",
       "`Sequential` provides training and inference features on this model.\n",
       "\n",
       "Examples:\n",
       "\n",
       "```python\n",
       "# Optionally, the first layer can receive an `input_shape` argument:\n",
       "model = tf.keras.Sequential()\n",
       "model.add(tf.keras.layers.Dense(8, input_shape=(16,)))\n",
       "# Afterwards, we do automatic shape inference:\n",
       "model.add(tf.keras.layers.Dense(4))\n",
       "\n",
       "# This is identical to the following:\n",
       "model = tf.keras.Sequential()\n",
       "model.add(tf.keras.Input(shape=(16,)))\n",
       "model.add(tf.keras.layers.Dense(8))\n",
       "\n",
       "# Note that you can also omit the `input_shape` argument.\n",
       "# In that case the model doesn't have any weights until the first call\n",
       "# to a training/evaluation method (since it isn't yet built):\n",
       "model = tf.keras.Sequential()\n",
       "model.add(tf.keras.layers.Dense(8))\n",
       "model.add(tf.keras.layers.Dense(4))\n",
       "# model.weights not created yet\n",
       "\n",
       "# Whereas if you specify the input shape, the model gets built\n",
       "# continuously as you are adding layers:\n",
       "model = tf.keras.Sequential()\n",
       "model.add(tf.keras.layers.Dense(8, input_shape=(16,)))\n",
       "model.add(tf.keras.layers.Dense(4))\n",
       "len(model.weights)\n",
       "# Returns \"4\"\n",
       "\n",
       "# When using the delayed-build pattern (no input shape specified), you can\n",
       "# choose to manually build your model by calling\n",
       "# `build(batch_input_shape)`:\n",
       "model = tf.keras.Sequential()\n",
       "model.add(tf.keras.layers.Dense(8))\n",
       "model.add(tf.keras.layers.Dense(4))\n",
       "model.build((None, 16))\n",
       "len(model.weights)\n",
       "# Returns \"4\"\n",
       "\n",
       "# Note that when using the delayed-build pattern (no input shape specified),\n",
       "# the model gets built the first time you call `fit`, `eval`, or `predict`,\n",
       "# or the first time you call the model on some input data.\n",
       "model = tf.keras.Sequential()\n",
       "model.add(tf.keras.layers.Dense(8))\n",
       "model.add(tf.keras.layers.Dense(1))\n",
       "model.compile(optimizer='sgd', loss='mse')\n",
       "# This builds the model for the first time:\n",
       "model.fit(x, y, batch_size=32, epochs=10)\n",
       "```\n",
       "\u001b[1;31mInit docstring:\u001b[0m\n",
       "Creates a `Sequential` model instance.\n",
       "\n",
       "Args:\n",
       "  layers: Optional list of layers to add to the model.\n",
       "  name: Optional name for the model.\n",
       "\u001b[1;31mCall docstring:\u001b[0m\n",
       "Wraps `call`, applying pre- and post-processing steps.\n",
       "\n",
       "Args:\n",
       "  *args: Positional arguments to be passed to `self.call`.\n",
       "  **kwargs: Keyword arguments to be passed to `self.call`.\n",
       "\n",
       "Returns:\n",
       "  Output tensor(s).\n",
       "\n",
       "Note:\n",
       "  - The following optional keyword arguments are reserved for specific uses:\n",
       "    * `training`: Boolean scalar tensor of Python boolean indicating\n",
       "      whether the `call` is meant for training or inference.\n",
       "    * `mask`: Boolean input mask.\n",
       "  - If the layer's `call` method takes a `mask` argument (as some Keras\n",
       "    layers do), its default value will be set to the mask generated\n",
       "    for `inputs` by the previous layer (if `input` did come from\n",
       "    a layer that generated a corresponding mask, i.e. if it came from\n",
       "    a Keras layer with masking support.\n",
       "  - If the layer is not built, the method will call `build`.\n",
       "\n",
       "Raises:\n",
       "  ValueError: if the layer's `call` method returns None (an invalid value).\n",
       "  RuntimeError: if `super().__init__()` was not called in the constructor.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d2c0eb4-cecc-486f-aac7-31685af19a07",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0munits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0muse_bias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'glorot_uniform'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbias_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'zeros'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkernel_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbias_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mactivity_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkernel_constraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbias_constraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Just your regular densely-connected NN layer.\n",
       "\n",
       "`Dense` implements the operation:\n",
       "`output = activation(dot(input, kernel) + bias)`\n",
       "where `activation` is the element-wise activation function\n",
       "passed as the `activation` argument, `kernel` is a weights matrix\n",
       "created by the layer, and `bias` is a bias vector created by the layer\n",
       "(only applicable if `use_bias` is `True`). These are all attributes of\n",
       "`Dense`.\n",
       "\n",
       "Note: If the input to the layer has a rank greater than 2, then `Dense`\n",
       "computes the dot product between the `inputs` and the `kernel` along the\n",
       "last axis of the `inputs` and axis 0 of the `kernel` (using `tf.tensordot`).\n",
       "For example, if input has dimensions `(batch_size, d0, d1)`,\n",
       "then we create a `kernel` with shape `(d1, units)`, and the `kernel` operates\n",
       "along axis 2 of the `input`, on every sub-tensor of shape `(1, 1, d1)`\n",
       "(there are `batch_size * d0` such sub-tensors).\n",
       "The output in this case will have shape `(batch_size, d0, units)`.\n",
       "\n",
       "Besides, layer attributes cannot be modified after the layer has been called\n",
       "once (except the `trainable` attribute).\n",
       "When a popular kwarg `input_shape` is passed, then keras will create\n",
       "an input layer to insert before the current layer. This can be treated\n",
       "equivalent to explicitly defining an `InputLayer`.\n",
       "\n",
       "Example:\n",
       "\n",
       ">>> # Create a `Sequential` model and add a Dense layer as the first layer.\n",
       ">>> model = tf.keras.models.Sequential()\n",
       ">>> model.add(tf.keras.Input(shape=(16,)))\n",
       ">>> model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
       ">>> # Now the model will take as input arrays of shape (None, 16)\n",
       ">>> # and output arrays of shape (None, 32).\n",
       ">>> # Note that after the first layer, you don't need to specify\n",
       ">>> # the size of the input anymore:\n",
       ">>> model.add(tf.keras.layers.Dense(32))\n",
       ">>> model.output_shape\n",
       "(None, 32)\n",
       "\n",
       "Args:\n",
       "  units: Positive integer, dimensionality of the output space.\n",
       "  activation: Activation function to use.\n",
       "    If you don't specify anything, no activation is applied\n",
       "    (ie. \"linear\" activation: `a(x) = x`).\n",
       "  use_bias: Boolean, whether the layer uses a bias vector.\n",
       "  kernel_initializer: Initializer for the `kernel` weights matrix.\n",
       "  bias_initializer: Initializer for the bias vector.\n",
       "  kernel_regularizer: Regularizer function applied to\n",
       "    the `kernel` weights matrix.\n",
       "  bias_regularizer: Regularizer function applied to the bias vector.\n",
       "  activity_regularizer: Regularizer function applied to\n",
       "    the output of the layer (its \"activation\").\n",
       "  kernel_constraint: Constraint function applied to\n",
       "    the `kernel` weights matrix.\n",
       "  bias_constraint: Constraint function applied to the bias vector.\n",
       "\n",
       "Input shape:\n",
       "  N-D tensor with shape: `(batch_size, ..., input_dim)`.\n",
       "  The most common situation would be\n",
       "  a 2D input with shape `(batch_size, input_dim)`.\n",
       "\n",
       "Output shape:\n",
       "  N-D tensor with shape: `(batch_size, ..., units)`.\n",
       "  For instance, for a 2D input with shape `(batch_size, input_dim)`,\n",
       "  the output would have shape `(batch_size, units)`.\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\tolga\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\keras\\layers\\core\\dense.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fcfc43-d38b-47d9-8f75-242bd5474dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
